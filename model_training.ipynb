{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Training\n",
    "Python notebook to load and transform data (using data_transformation.py), model training and testing, loading and predicting on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "import data_transformation #custom python file for data preprocessing and transformation\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory = r'C:\\Priyanka\\job_application_2024\\JPMorganChase\\Take Home Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>application_approved_flag</th>\n",
       "      <th>internal_score</th>\n",
       "      <th>bad_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000001</td>\n",
       "      <td>22419852</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>22.15%</td>\n",
       "      <td>8 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.10%</td>\n",
       "      <td>16200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14877.170280</td>\n",
       "      <td>36809</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000002</td>\n",
       "      <td>22349118</td>\n",
       "      <td>1400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.24%</td>\n",
       "      <td>6 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.50%</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4097.304770</td>\n",
       "      <td>19536</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000003</td>\n",
       "      <td>22398818</td>\n",
       "      <td>7000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.49%</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>68900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.10%</td>\n",
       "      <td>11900</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12688.495160</td>\n",
       "      <td>241465</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000004</td>\n",
       "      <td>22419015</td>\n",
       "      <td>18000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>16.29%</td>\n",
       "      <td>9 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.10%</td>\n",
       "      <td>7600</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7908.799817</td>\n",
       "      <td>179757</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000005</td>\n",
       "      <td>22388614</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.99%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.90%</td>\n",
       "      <td>21000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19378.561060</td>\n",
       "      <td>31953</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  member_id  loan_amnt        term int_rate emp_length  \\\n",
       "0  20000001   22419852      10000   36 months   22.15%    8 years   \n",
       "1  20000002   22349118       1400   36 months   18.24%    6 years   \n",
       "2  20000003   22398818       7000   36 months   12.49%    3 years   \n",
       "3  20000004   22419015      18000   60 months   16.29%    9 years   \n",
       "4  20000005   22388614      12000   36 months   12.99%  10+ years   \n",
       "\n",
       "  home_ownership  annual_inc desc             purpose  ...  inq_last_6mths  \\\n",
       "0           RENT     37000.0  NaN  debt_consolidation  ...               1   \n",
       "1           RENT     41000.0  NaN               other  ...               0   \n",
       "2           RENT     68900.0  NaN  debt_consolidation  ...               0   \n",
       "3       MORTGAGE     41000.0  NaN  debt_consolidation  ...               1   \n",
       "4       MORTGAGE     64000.0  NaN    home_improvement  ...               0   \n",
       "\n",
       "   mths_since_recent_inq  revol_util  total_bc_limit  \\\n",
       "0                    3.0      73.10%           16200   \n",
       "1                    9.0      11.50%            4000   \n",
       "2                   11.0      48.10%           11900   \n",
       "3                    0.0      38.10%            7600   \n",
       "4                    NaN      57.90%           21000   \n",
       "\n",
       "   mths_since_last_major_derog tot_hi_cred_lim  tot_cur_bal  \\\n",
       "0                          NaN    14877.170280        36809   \n",
       "1                          NaN     4097.304770        19536   \n",
       "2                         80.0    12688.495160       241465   \n",
       "3                         73.0     7908.799817       179757   \n",
       "4                          NaN    19378.561060        31953   \n",
       "\n",
       "   application_approved_flag  internal_score  bad_flag  \n",
       "0                          1             131       NaN  \n",
       "1                          1              19       NaN  \n",
       "2                          1              92       NaN  \n",
       "3                          1             235       NaN  \n",
       "4                          1             157       NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the testing data\n",
    "test_data = pd.read_csv(os.path.join(directory, 'testing_loan_data.csv'))\n",
    "test_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>application_approved_flag</th>\n",
       "      <th>internal_score</th>\n",
       "      <th>bad_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>11983056.0</td>\n",
       "      <td>7550</td>\n",
       "      <td>36 months</td>\n",
       "      <td>16.24%</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72%</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3828.953801</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>12002921.0</td>\n",
       "      <td>27050</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.99%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; Combining high ...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.20%</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34359.940730</td>\n",
       "      <td>114834.0</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>11983096.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.99%</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; I would like to...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24%</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16416.617760</td>\n",
       "      <td>7137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>12003142.0</td>\n",
       "      <td>28000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.62%</td>\n",
       "      <td>5 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.60%</td>\n",
       "      <td>42200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38014.149760</td>\n",
       "      <td>799592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000005</td>\n",
       "      <td>11993233.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.53%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.80%</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6471.462236</td>\n",
       "      <td>13605.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   member_id  loan_amnt        term int_rate emp_length  \\\n",
       "0  10000001  11983056.0       7550   36 months   16.24%    3 years   \n",
       "1  10000002  12002921.0      27050   36 months   10.99%  10+ years   \n",
       "2  10000003  11983096.0      12000   36 months   10.99%    4 years   \n",
       "3  10000004  12003142.0      28000   36 months    7.62%    5 years   \n",
       "4  10000005  11993233.0      12000   36 months   13.53%  10+ years   \n",
       "\n",
       "  home_ownership  annual_inc  \\\n",
       "0           RENT     28000.0   \n",
       "1            OWN     55000.0   \n",
       "2           RENT     60000.0   \n",
       "3       MORTGAGE    325000.0   \n",
       "4           RENT     40000.0   \n",
       "\n",
       "                                                desc             purpose  ...  \\\n",
       "0                                                NaN  debt_consolidation  ...   \n",
       "1    Borrower added on 12/31/13 > Combining high ...  debt_consolidation  ...   \n",
       "2    Borrower added on 12/31/13 > I would like to...  debt_consolidation  ...   \n",
       "3                                                NaN  debt_consolidation  ...   \n",
       "4                                                NaN  debt_consolidation  ...   \n",
       "\n",
       "   inq_last_6mths  mths_since_recent_inq  revol_util  total_bc_limit  \\\n",
       "0             0.0                   17.0         72%          4000.0   \n",
       "1             0.0                    8.0      61.20%         35700.0   \n",
       "2             1.0                    3.0         24%         18100.0   \n",
       "3             1.0                    3.0      54.60%         42200.0   \n",
       "4             0.0                   17.0      68.80%          7000.0   \n",
       "\n",
       "   mths_since_last_major_derog tot_hi_cred_lim  tot_cur_bal  \\\n",
       "0                          NaN     3828.953801       5759.0   \n",
       "1                          NaN    34359.940730     114834.0   \n",
       "2                          NaN    16416.617760       7137.0   \n",
       "3                          NaN    38014.149760     799592.0   \n",
       "4                         53.0     6471.462236      13605.0   \n",
       "\n",
       "   application_approved_flag  internal_score  bad_flag  \n",
       "0                          1              99       0.0  \n",
       "1                          1             353       0.0  \n",
       "2                          1             157       0.0  \n",
       "3                          1             365       0.0  \n",
       "4                          1             157       0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the training data\n",
    "data = pd.read_csv(os.path.join(directory, 'training_loan_data.csv'), header=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "- remove duplicates based on analysis in data_analysis file\n",
    "- split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep='first', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.dropna(subset=['bad_flag'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "## Separating Independent and Dependent Columns\n",
    "X = data.drop(['bad_flag'],axis=1)\n",
    "Y = data[['bad_flag']]\n",
    "\n",
    "# Splitting the dataset into the Training and Testing set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Transformation\n",
    "- Remove the unnecessary features based on EDA.\n",
    "- feature engineering: convert int_rate, revol_util, emp_length into numerical \n",
    "- For categorical features:\n",
    "    - combine less frequent categories into 'other'\n",
    "    - impute missing values using Simple Imputer with 'most_frequent' strategy\n",
    "    - Perform label encoding for emp_length feature to store the order, one hot encoding for rest of the categorical features\n",
    "- For numerical features:\n",
    "    - Impute missing values using Simple Imputer with 'median' strategy\n",
    "    - power tranformation to handle skewed data using 'yeo-johnson' method\n",
    "    - scaling using Robust scalar since it handles outlier as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs preprocessing steps on training, validation (x_test) and testing dataset (test_dataset)\n",
    "x_train = data_transformation.preprocessor(x_train)\n",
    "x_test = data_transformation.preprocessor(x_test)\n",
    "test_dataset = data_transformation.preprocessor(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs data transfomation steps on training, validation (x_test) and testing dataset (test_dataset) to prepare for the model training\n",
    "x_train, x_test, test_dataset = data_transformation.data_transformation(x_train, x_test, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>emp_length_yr</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_NONE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132105</th>\n",
       "      <td>-0.744250</td>\n",
       "      <td>0.497295</td>\n",
       "      <td>-1.036162</td>\n",
       "      <td>0.878352</td>\n",
       "      <td>0.871195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.569646</td>\n",
       "      <td>-1.004436</td>\n",
       "      <td>-0.619818</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269</th>\n",
       "      <td>-0.186837</td>\n",
       "      <td>-0.502705</td>\n",
       "      <td>0.225379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146847</td>\n",
       "      <td>1.541472</td>\n",
       "      <td>-0.168957</td>\n",
       "      <td>1.424469</td>\n",
       "      <td>-0.381477</td>\n",
       "      <td>1.388520</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>-0.288750</td>\n",
       "      <td>-0.182136</td>\n",
       "      <td>0.071567</td>\n",
       "      <td>-0.346551</td>\n",
       "      <td>-0.230385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.358675</td>\n",
       "      <td>-0.256438</td>\n",
       "      <td>0.376650</td>\n",
       "      <td>-0.250905</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94628</th>\n",
       "      <td>-0.181905</td>\n",
       "      <td>0.038985</td>\n",
       "      <td>-0.049851</td>\n",
       "      <td>-0.537205</td>\n",
       "      <td>-0.590745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.641363</td>\n",
       "      <td>-0.364447</td>\n",
       "      <td>-0.871290</td>\n",
       "      <td>-0.366942</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179406</th>\n",
       "      <td>-1.296275</td>\n",
       "      <td>-1.119014</td>\n",
       "      <td>-0.539874</td>\n",
       "      <td>0.313824</td>\n",
       "      <td>0.450887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544429</td>\n",
       "      <td>0.615194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609542</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amnt  int_rate  annual_inc  percent_bc_gt_75       dti  \\\n",
       "132105  -0.744250  0.497295   -1.036162          0.878352  0.871195   \n",
       "129269  -0.186837 -0.502705    0.225379          0.000000  0.146847   \n",
       "29902   -0.288750 -0.182136    0.071567         -0.346551 -0.230385   \n",
       "94628   -0.181905  0.038985   -0.049851         -0.537205 -0.590745   \n",
       "179406  -1.296275 -1.119014   -0.539874          0.313824  0.450887   \n",
       "\n",
       "        inq_last_6mths  mths_since_recent_inq  total_bc_limit  tot_cur_bal  \\\n",
       "132105        1.000000               0.000000       -0.569646    -1.004436   \n",
       "129269        1.541472              -0.168957        1.424469    -0.381477   \n",
       "29902         1.000000              -0.358675       -0.256438     0.376650   \n",
       "94628         1.000000              -1.641363       -0.364447    -0.871290   \n",
       "179406        0.000000               0.544429        0.615194     0.000000   \n",
       "\n",
       "        tot_hi_cred_lim  emp_length_yr  home_ownership_MORTGAGE  \\\n",
       "132105        -0.619818              4                      0.0   \n",
       "129269         1.388520              8                      1.0   \n",
       "29902         -0.250905              2                      1.0   \n",
       "94628         -0.366942              3                      0.0   \n",
       "179406         0.609542              8                      1.0   \n",
       "\n",
       "        home_ownership_NONE  home_ownership_OTHER  home_ownership_RENT  \\\n",
       "132105                  0.0                   0.0                  1.0   \n",
       "129269                  0.0                   0.0                  0.0   \n",
       "29902                   0.0                   0.0                  0.0   \n",
       "94628                   0.0                   0.0                  1.0   \n",
       "179406                  0.0                   0.0                  0.0   \n",
       "\n",
       "        purpose_credit_card  purpose_debt_consolidation  purpose_other  \\\n",
       "132105                  0.0                         1.0            0.0   \n",
       "129269                  0.0                         1.0            0.0   \n",
       "29902                   0.0                         1.0            0.0   \n",
       "94628                   0.0                         1.0            0.0   \n",
       "179406                  0.0                         0.0            1.0   \n",
       "\n",
       "        term_ 36 months  term_ 60 months  \n",
       "132105              1.0              0.0  \n",
       "129269              1.0              0.0  \n",
       "29902               1.0              0.0  \n",
       "94628               1.0              0.0  \n",
       "179406              1.0              0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>emp_length_yr</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_NONE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186837</td>\n",
       "      <td>1.194210</td>\n",
       "      <td>-0.803111</td>\n",
       "      <td>0.547422</td>\n",
       "      <td>0.979636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.576785</td>\n",
       "      <td>0.091363</td>\n",
       "      <td>-0.422867</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.531172</td>\n",
       "      <td>0.641545</td>\n",
       "      <td>-0.640255</td>\n",
       "      <td>-1.333680</td>\n",
       "      <td>0.825399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423215</td>\n",
       "      <td>-0.925480</td>\n",
       "      <td>-0.726601</td>\n",
       "      <td>-0.909975</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.515171</td>\n",
       "      <td>-0.266915</td>\n",
       "      <td>0.159378</td>\n",
       "      <td>0.191038</td>\n",
       "      <td>-0.983831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658250</td>\n",
       "      <td>-0.171443</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>-0.118333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467791</td>\n",
       "      <td>0.348238</td>\n",
       "      <td>-0.640255</td>\n",
       "      <td>-0.346551</td>\n",
       "      <td>0.331823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.641363</td>\n",
       "      <td>-0.512060</td>\n",
       "      <td>0.488130</td>\n",
       "      <td>-0.482624</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.182136</td>\n",
       "      <td>0.048121</td>\n",
       "      <td>0.461045</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332373</td>\n",
       "      <td>-0.493409</td>\n",
       "      <td>0.255411</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  annual_inc  percent_bc_gt_75       dti  \\\n",
       "0  -0.186837  1.194210   -0.803111          0.547422  0.979636   \n",
       "1  -1.531172  0.641545   -0.640255         -1.333680  0.825399   \n",
       "2  -0.515171 -0.266915    0.159378          0.191038 -0.983831   \n",
       "3   0.467791  0.348238   -0.640255         -0.346551  0.331823   \n",
       "4   0.000000 -0.182136    0.048121          0.461045  0.665450   \n",
       "\n",
       "   inq_last_6mths  mths_since_recent_inq  total_bc_limit  tot_cur_bal  \\\n",
       "0             1.0              -0.576785        0.091363    -0.422867   \n",
       "1             0.0               0.423215       -0.925480    -0.726601   \n",
       "2             0.0               0.658250       -0.171443     0.684826   \n",
       "3             1.0              -1.641363       -0.512060     0.488130   \n",
       "4             0.0               0.000000        0.332373    -0.493409   \n",
       "\n",
       "   tot_hi_cred_lim  emp_length_yr  home_ownership_MORTGAGE  \\\n",
       "0         0.016518              9                      0.0   \n",
       "1        -0.909975              7                      0.0   \n",
       "2        -0.118333              4                      0.0   \n",
       "3        -0.482624             10                      1.0   \n",
       "4         0.255411              2                      1.0   \n",
       "\n",
       "   home_ownership_NONE  home_ownership_OTHER  home_ownership_RENT  \\\n",
       "0                  0.0                   0.0                  1.0   \n",
       "1                  0.0                   0.0                  1.0   \n",
       "2                  0.0                   0.0                  1.0   \n",
       "3                  0.0                   0.0                  0.0   \n",
       "4                  0.0                   0.0                  0.0   \n",
       "\n",
       "   purpose_credit_card  purpose_debt_consolidation  purpose_other  \\\n",
       "0                  0.0                         1.0            0.0   \n",
       "1                  0.0                         0.0            1.0   \n",
       "2                  0.0                         1.0            0.0   \n",
       "3                  0.0                         1.0            0.0   \n",
       "4                  0.0                         0.0            1.0   \n",
       "\n",
       "   term_ 36 months  term_ 60 months  \n",
       "0              1.0              0.0  \n",
       "1              1.0              0.0  \n",
       "2              1.0              0.0  \n",
       "3              0.0              1.0  \n",
       "4              1.0              0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "My intial plan was to create data processing pipeline using sklearn.pipeline and store it in pickle file for /validationtesting dataset. But, the data was not properly transformed\n",
    "and I ran out of time, hence I went to above naive approach where I am doing fit_transform on training set and transform on validation and testing set at same time\n",
    "to avoid data leakage problem. This would have been simpler and clearer with sklearn pipeline. I have kept the commented code in data_transformation.py file in case someone wants to refer it.\n",
    "'''\n",
    "'''\n",
    "import pickle\n",
    "x_train = data_transformation.preprocessor(x_train)\n",
    "x_test = data_transformation.preprocessor(x_test)\n",
    "\n",
    "pipeline = data_transformation.init_pipeline()\n",
    "pipeline.fit_transform(x_train)\n",
    "pipeline.transform(x_test)\n",
    "with open('model_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply oversampling technique - SMOTE to balance the training set. \n",
    "Dataset contains 7% positive class and 93% negatvie class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_sm , y_sm = smote.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Oversampling - SMOTE, the shape of x_train: (279992, 20)\n",
      "After Oversampling - SMOTE, the shape of y_train: (279992, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After Oversampling - SMOTE, the shape of x_train: {}\".format(x_sm.shape))\n",
    "print(\"After Oversampling - SMOTE, the shape of y_train: {} \\n\".format(y_sm.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The problem is to predict whether the loan will defualt or not i.e. bad_loan = 1 or 0. \n",
    "Since the data is highly imbalanced, it is not good idea to only evaluate accuracy. Accuracy is true_predicted/total, so e.g. if model is predicting class 0 correctly 90% of the time, it will not give correct picture of how well the model is predicting positive class. \n",
    "\n",
    "Hence we will evalute Precision and Recall (F1-Score) scores:\n",
    "Precision is important in this scenario because you want to minimize the number of false positives, i.e., approve only those applicants who are less likely to default. If a false positive (approving a bad loan) occurs, it could lead to a financial loss for the lender.\n",
    "\n",
    "Recall is also crucial because you want to maximize the detection of all the bad loans (defaults). If a false negative (missing a bad loan applicant) happens, it means you are missing potential defaults, which could also be costly.\n",
    "\n",
    "F1-Score: The F1-score combines both precision and recall into a single metric by calculating their harmonic mean. It's a good choice when you want to balance both precision and recall and ensure that both false positives and false negatives are minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture: \n",
    "- Architecture: 2 hiddle layers and one output layer: 20-(10-10)-1\n",
    "- Generally, small number of neurons are good for small NN. I tried 8, 10 and 16 for both hidden layers\n",
    "- Chose Activation function as ReLU for hidden layers and Sigmoid function for output.\n",
    "- The sigmoid function is used in the output layer. This is standard for binary classification problems because the sigmoid function outputs a value between 0 and 1\n",
    "- Binary Cross-Entropy Loss (BCELoss): This loss function is commonly used for binary classification tasks. It calculates the difference between the predicted probability (from the output layer) and the true label (0 or 1).\n",
    "- class_weights = torch.tensor([10.0]). This is especially useful in imbalanced datasets, where one class (e.g., good loans) might dominate.\n",
    "- Adam Optimizer: The Adam optimizer is chosen here due to its effectiveness in training deep neural networks. It adapts the learning rate for each parameter, making it more efficient and faster than standard stochastic gradient descent (SGD). This optimizer is generally a good choice when starting, as it requires less fine-tuning of the learning rate compared to SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7442,  0.4973, -1.0362,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.1868, -0.5027,  0.2254,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.2888, -0.1821,  0.0716,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0100,  0.8431, -0.8360,  ...,  1.0000,  1.0000,  0.0000],\n",
      "        [ 0.9719,  0.6312,  0.1385,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [-0.3694,  0.2740, -1.0684,  ...,  0.0000,  1.0000,  0.0000]])\n",
      "Training the model...\n",
      "Epoch [1/50], Loss: 0.0000\n",
      "Epoch [2/50], Loss: 0.0000\n",
      "Epoch [3/50], Loss: 0.0000\n",
      "Epoch [4/50], Loss: 0.0000\n",
      "Epoch [5/50], Loss: 0.0000\n",
      "Epoch [6/50], Loss: 0.0000\n",
      "Epoch [7/50], Loss: 0.0000\n",
      "Epoch [8/50], Loss: 0.0000\n",
      "Epoch [9/50], Loss: 0.0000\n",
      "Epoch [10/50], Loss: 0.0000\n",
      "Epoch [11/50], Loss: 0.0000\n",
      "Epoch [12/50], Loss: 0.0000\n",
      "Epoch [13/50], Loss: 0.0000\n",
      "Epoch [14/50], Loss: 0.0000\n",
      "Epoch [15/50], Loss: 0.0000\n",
      "Epoch [16/50], Loss: 0.0000\n",
      "Epoch [17/50], Loss: 0.0000\n",
      "Epoch [18/50], Loss: 0.0000\n",
      "Epoch [19/50], Loss: 0.0000\n",
      "Epoch [20/50], Loss: 0.0000\n",
      "Epoch [21/50], Loss: 0.0000\n",
      "Epoch [22/50], Loss: 0.0000\n",
      "Epoch [23/50], Loss: 0.0000\n",
      "Epoch [24/50], Loss: 0.0000\n",
      "Epoch [25/50], Loss: 0.0000\n",
      "Epoch [26/50], Loss: 0.0000\n",
      "Epoch [27/50], Loss: 0.0000\n",
      "Epoch [28/50], Loss: 0.0000\n",
      "Epoch [29/50], Loss: 0.0000\n",
      "Epoch [30/50], Loss: 0.0000\n",
      "Epoch [31/50], Loss: 0.0000\n",
      "Epoch [32/50], Loss: 0.0000\n",
      "Epoch [33/50], Loss: 0.0000\n",
      "Epoch [34/50], Loss: 0.0000\n",
      "Epoch [35/50], Loss: 0.0000\n",
      "Epoch [36/50], Loss: 0.0000\n",
      "Epoch [37/50], Loss: 0.0000\n",
      "Epoch [38/50], Loss: 0.0000\n",
      "Epoch [39/50], Loss: 0.0000\n",
      "Epoch [40/50], Loss: 0.0000\n",
      "Epoch [41/50], Loss: 0.0000\n",
      "Epoch [42/50], Loss: 0.0000\n",
      "Epoch [43/50], Loss: 0.0000\n",
      "Epoch [44/50], Loss: 0.0000\n",
      "Epoch [45/50], Loss: 0.0000\n",
      "Epoch [46/50], Loss: 0.0000\n",
      "Epoch [47/50], Loss: 0.0000\n",
      "Epoch [48/50], Loss: 0.0000\n",
      "Epoch [49/50], Loss: 0.0000\n",
      "Epoch [50/50], Loss: 0.0000\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 10]             210\n",
      "              ReLU-2                   [-1, 10]               0\n",
      "            Linear-3                   [-1, 10]             110\n",
      "              ReLU-4                   [-1, 10]               0\n",
      "            Linear-5                    [-1, 1]              11\n",
      "           Sigmoid-6                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 331\n",
      "Trainable params: 331\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "\n",
      "Performing inference on test dataset...\n",
      "Value Loss: 6.68601655960083\n",
      "Predictions: 37625\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_neurons, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_neurons)  # Hidden layer (20, 10)\n",
    "        self.hidden2 = nn.Linear(hidden_neurons, hidden_neurons)  # Hidden layer (10, 10)\n",
    "        self.output = nn.Linear(hidden_neurons, output_size)  # Output layer (10,1)\n",
    "        self.activation = nn.ReLU()  # Activation function for hidden layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Activation function for output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)  # Pass through first hidden layer\n",
    "        x = self.activation(x)  # Apply activation function (ReLU) after first hidden layer\n",
    "        x = self.hidden2(x)  # Pass through second hidden layer\n",
    "        x = self.activation(x)  # Apply activation function (ReLU) after second hidden layer\n",
    "        x = self.output(x)  # Pass through output layer\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, x_train_tensor, y_train_tensor, criterion, optimizer, epochs=20):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(x_train_tensor)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), y_train_tensor.squeeze())  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(x_train_tensor):.4f}\")\n",
    "    \n",
    "\n",
    "# Inference function\n",
    "def inference(model, x_test_tensor, y_test_tensor):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_test_tensor)  # Forward pass\n",
    "        val_loss = criterion(outputs.squeeze(), y_test_tensor.squeeze())\n",
    "        print(f\"Value Loss: {val_loss.item()}\")\n",
    "        predicted = (outputs.squeeze() > 0.5).float()  # Binary classification threshold\n",
    "        predictions.extend(predicted.tolist())\n",
    "    return predictions\n",
    "\n",
    "# Example Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Convert data to PyTorch tensors\n",
    "    x_train_tensor = torch.tensor(x_sm.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_sm.values, dtype=torch.float32)\n",
    "    x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "    print(x_train_tensor)\n",
    "    # Define model, loss function, and optimizer\n",
    "    input_size = x_train_tensor.shape[1]\n",
    "    hidden_neurons = 10  # Configurable hidden layer size\n",
    "    output_size = 1  # Single output for binary classification\n",
    "\n",
    "    model = NeuralNetwork(input_size, hidden_neurons, output_size)\n",
    "    class_weights = torch.tensor([10.0])  # Example weight for minority class (adjust as needed)\n",
    "    #criterion = nn.BCEWithLogitsLoss(weight=class_weights) # This BCEWithLogitsLoss did not give me better result than BCELoss.\n",
    "    criterion = nn.BCELoss(weight=class_weights)  # Binary Cross-Entropy Loss\n",
    "    learning_rate = 0.0001 \n",
    "    epochs = 50\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=learning_rate) # This optimizer did not give me better result than Adam.\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training the model...\")\n",
    "    train_model(model, x_train_tensor, y_train_tensor, criterion, optimizer, epochs=epochs)\n",
    "    print(summary(model, input_size=(input_size,)))\n",
    "    # Perform inference\n",
    "    print(\"\\nPerforming inference on test dataset...\")\n",
    "    \n",
    "    predictions = inference(model, x_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Output predictions\n",
    "    print(\"Predictions:\", len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to plot the confusion_matrix of a classification model built using sklearn\n",
    "def confusion_matrix_and_report(y_pred, y_test_tensor):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix, based on the threshold specified, with percentages\n",
    "\n",
    "    model: classifier\n",
    "    features: independent variables\n",
    "    target: dependent variable\n",
    "    threshold: threshold for the prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_test_tensor.squeeze(), y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "    #Accuracy as per the classification report \n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    cr=classification_report(y_test_tensor.squeeze(),y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.62      0.75     34999\n",
      "         1.0       0.10      0.53      0.16      2626\n",
      "\n",
      "    accuracy                           0.62     37625\n",
      "   macro avg       0.52      0.58      0.46     37625\n",
      "weighted avg       0.89      0.62      0.71     37625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_and_report(predictions, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.16180479034970713\n",
      "precision_score: 0.09543682014093179\n",
      "recall_score: 0.5312261995430312\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "print(\"f1_score: {}\".format(f1_score(y_test_tensor.squeeze(), predictions)))\n",
    "print(\"precision_score: {}\".format(precision_score(y_test_tensor.squeeze(), predictions)))\n",
    "print(\"recall_score: {}\".format(recall_score(y_test_tensor.squeeze(), predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Analysis:\n",
    "- Precision: Precision is low, meaning that many of the positive predictions made by the model are actually false positives. This implies that the model is overly confident about predicting the bad loans (defaults), but many of those predictions are wrong.\n",
    "\n",
    "- Recall: Recall is higher, meaning the model is doing a good job of identifying actual bad loans. However, with low precision, many of these \"identified\" bad loans are false positives.\n",
    "\n",
    "- F1-Score: The F1-score combines precision and recall, and since precision is so low, the F1-score is significantly impacted. The low F1-score suggests that the model’s overall performance is poor and needs improvement.\n",
    "\n",
    "- To improve the performance I tried:\n",
    "    - different multiple hidden layers: 1 and 2\n",
    "    - epochs: ranging from 20 to 50, \n",
    "    - learnign rate: 0.01, 0.001, 0.001\n",
    "    - class weights: 2, 10, 50, 90\n",
    "    - different optimizers: ADAM, SGD\n",
    "    - Trained the model with SMOTE and without SMOTE data\n",
    "    - threshold tuning: 0.5, 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model for future purpose\n",
    "torch.save(model.state_dict(),'model_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the pipeline from the file\\nwith open('model_pipeline.pkl', 'rb') as f:\\n    pipeline = pickle.load(f)\\ntest_dataset = data_transformation.preprocessor(test_data)\\ntest_dataset = pipeline.transform(test_dataset)\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' This code is call the pipeline for data transformation on testing data'''\n",
    "'''\n",
    "# Load the pipeline from the file\n",
    "with open('model_pipeline.pkl', 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "test_dataset = data_transformation.preprocessor(test_data)\n",
    "test_dataset = pipeline.transform(test_dataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting test dataset into pytorch tensors for predictions\n",
    "test_dataset_tensor = torch.tensor(test_dataset.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model for prediction.\n",
    "model.load_state_dict(torch.load('model_full.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Make prediction using the loaded model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_dataset_tensor)  # Forward pass\n",
    "    predicted = (outputs.squeeze() > 0.5).float()  # Binary classification threshold\n",
    "    predictions.extend(predicted.tolist())\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions into bad_flag column\n",
    "test_data['bad_flag']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "test_data.to_csv(os.path.join(directory, 'testing_loan_data_predicted.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
